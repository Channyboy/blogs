---
layout: post
title: "Forwarding Open Liberty logs in OpenShift Container Platform to external logging solutions using Log Forwarding API"
categories: blog
author_picture: https://avatars3.githubusercontent.com/leemelim
author_github: https://github.com/leemelim
seo-title: Forwarding Open Liberty logs in OpenShift Container Platform to external logging solutions using Log Forwarding API - OpenLiberty.io
seo-description: Using Log Forwarding API, you can send logs from Open Liberty deployed in OpenShift Container Platform to remote destinations. Logs, which get collected by cluster logging in OpenShift Container Platform, can be forwarded to either external Elasticsearch cluster or external log aggregation solution using the Fluentd forward protocol.
blog_description: Using Log Forwarding API, you can send logs from Open Liberty deployed in OpenShift Container Platform to remote destinations. Logs, which get collected by cluster logging in OpenShift Container Platform, can be forwarded to either external Elasticsearch cluster or external log aggregation solution using the Fluentd forward protocol.
---
= Forwarding Open Liberty logs in OpenShift Container Platform to external logging solutions using Log Forwarding API
Halim Lee <https://github.com/leemelim>

Container orchestration system is highly distributed and its parts are dynamic. It becomes difficult to detect which worker nodes are running your containers and pods for your application. Application logging and log collection help you monitor and troubleshoot these applications efficiently. OpenShift Container Platform provides a log aggregation solution with cluster logging, which is consisted of three components: Elasticsearch, Fluentd, and Kibana (EFK). Despite the log aggregation solution provided within OpenShift Cluster Platform, forwarding logs to external locations may be essential. You may already have exisiting log analysis solutions to monitor applications outside of OpenShift Cluster. To aggregate all logs, both logs inside and outside of your OpenShift cluster, you would want to ship the logs generated within OpenShift environment to your exisiting solutions.

Starting OpenShift 4.3, you can use Log Forwarding API to send logs to external sources. It makes it possible for you to use external log analysis tools for Open Liberty running on your OpenShift cluster. The Log Forwarding API enables you to configure custom pipelines to send logs to specific endpoints within or outside of your OpenShift cluster. 

image::/img/blog/log-forwarding.png[Log Forwarding,width=70%,align="center"]

== Configuring Log Forwarding API

. Ensure your cluster logging instance is created and all pods are fully operational. See the installation and configuration guide for cluster logging: link:https://docs.openshift.com/container-platform/4.4/logging/cluster-logging-deploying.html[Deploying cluster logging].

. Create a Log Forwarding instance object YAML file, `log-forward-instance.yaml`. Configure outputs and pipelines.
* Outputs can be either `elasticsearch` or `forward`. `elasticsearch` routes logs to internal or external Elasticsearch cluster. `forward` forwards logs to an external log aggregation solution and this option uses the Fluentd forward protocols.
* Pipelines can be one of `logs.app`, `logs.infra` and `logs.audit`. `logs.app` are container logs generated by user applications. `logs.infra` are logs generated by infrastructure components running in the cluster and OpenShift Container Platform nodes. `logs.audit` are logs generated by the node audit system, which are stored in the /var/log/audit/audit.log file.
* Sample `log-forward-instance.yaml`:
+
```
apiVersion: "logging.openshift.io/v1alpha1"
kind: "LogForwarding"
metadata:
  name: instance 
  namespace: openshift-logging
spec:
  disableDefaultForwarding: true 
  outputs: 
   - name: elasticsearch 
     type: "elasticsearch"  
     endpoint: elasticsearch.openshift-logging.svc:9200 
     secret: 
        name: fluentd
   - name: elasticsearch-insecure 
     type: "elasticsearch"  
     endpoint: http://elasticsearch-insecure.offcluster.com:9200 
     insecure: true
   - name: fluentd-forward
     type: "forward"
     endpoint: https://splunk-fluentd-forward.offcluster.com:24224
     secret:
        name: secure-forward
  pipelines: 
   - name: container-logs 
     inputSource: logs.app 
     outputRefs: 
     - elasticsearch
     - elasticsearch-insecure
     - fluentd-forward
   - name: infra-logs
     inputSource: logs.infra
     outputRefs:
     - elasticsearch
   - name: audit-logs
     inputSource: logs.audit
     outputRefs:
     - fluentd-forward
```
+
The example has three outputs defined, elasticsearch routing to internal Elasticsearch instance, elasticsearch routing to external insecure Elasticsearch cluster and forward routing to an instance of Fluentd. Each log type is defined under pipelines with its configured ouputs.

. Create the instance:
+
[source]
----
[root@ocp ~]# oc create -f log-forward-instance.yaml
----
+

. Annotate the ClusterLogging instance to enable the Log Forwarding API.
+
[source]
----
[root@ocp ~]# oc annotate clusterlogging -n openshift-logging instance clusterlogging.openshift.io/logforwardingtechpreview=enabled
----
+

. Liberty application pods output logs in JSON format, therefore it is recommended to set Fluentd to parse the JSON fields from the message body. This feature is disabled by default. To enable it, set the cluster logging instance's *managementState* field from *"Managed"* to *"Unmanaged"*.
+
```
[root@ocp ~]# oc edit ClusterLogging instance

apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"

....

spec:
  managementState: "Unmanaged"
```
+
Then, set the environment variable *MERGE_JSON_LOG* to *true*.
+
[source]
----
[root@ocp ~]# oc set env ds/fluentd MERGE_JSON_LOG=true
----
+

. To check if the logs are being forwarded to the specified outputs, run the following command:
+
[source]
----
[root@ocp ~]# oc -n openshift-logging get cm fluentd -o json | jq -r '.data."fluent.conf"' > fluentd-with-logfowarding.conf
----
+
This command gets ConfigMap configuration for Fluentd inside OpenShift Container Platform. Check if the outputs are defined inside the configuration file.

* For example:
+
```
...
<label @CONTAINER_LOGS>
  <match **>
    @type copy

    <store>
      @type relabel
      @label @ELASTICSEARCH
    </store>
    <store>
      @type relabel
      @label @ELASTICSEARCH-INSECURE
    </store>
    <store>
      @type relabel
      @label @FLUENTD-FORWARD
    </store>
  </match>
</label>
...
```
+


== Internal and External Splunk configuration

Using `forward` output, you can forward OpenShift Container Platform logs to Splunk using Fluentd forward protocol. You can setup Splunk inside your OpenShift Cluster or on your external machine.

=== Option 1: Deploying Splunk onto your OpenShift cluster

This option deploys an instance of Splunk inside your OpenShift cluster using a script. If you do not have Splunk deployed already, this option will make Splunk setup simple through a usage of pre-created configurations.

. Download and Install the following tools:
* Git
* OpenShift Command Line Tool
* Helm Command Line Tool

. Login to your OpenShift through command line tool with a user with `cluster-admin` permissions.

. Clone the git repository to your machine. The repository was retrieved from OpenShift blog post: link:https://www.openshift.com/blog/forwarding-logs-to-splunk-using-the-openshift-log-forwarding-api[Forwarding Logs to Splunk Using the OpenShift Log Forwarding API].
+
[source]
----
[root@ocp ~]# git clone https://github.com/sabre1041/openshift-logforwarding-splunk.git
[root@ocp ~]# cd openshift-logforwarding-splunk
----
+

. Deploy a nonpersistent instance of splunk to a project called `splunk`.
+
[source]
----
[root@ocp ~]# ./splunk-install.sh
----
+
Once splunk is deployed, you can login by discovering the exposed link.
+
[source]
----
[root@ocp ~]# echo https://$(oc get routes -n splunk splunk -o jsonpath='{.spec.host}')
----
+
The default credentials are:
+
```
Username: admin
Password: admin123
```
+

. Retrieve token value in Splunk's Settings > Data Inputs > HTTP Event Collector. Install the Helm chart to the OpenShift environment. Helm chart 
deploys the Fluentd forwarder and OpneShift Log Forwarding API components. Replace _<token>_ with token that you retrieved from Splunk.
+
[source]
----
[root@ocp ~]# helm upgrade -i --wnamespace=openshift-logging openshift-logforwarding-splunk charts/openshift-logforwarding-splunk/ --set forwarding.splunk.token=<token>
----
+
Confirm *openshift-logforwarding-splunk* pods are running.
+
[source]
----
[root@ocp ~]# oc get pods -n openshift-logging
----
+

=== Option 2: Setting up Splunk on your external machine

This option sets up Splunk manually on your external machine. If you already have Splunk deployed on your external machine, this option will help you setup the connection between your OpenShift cluster and Splunk. You can deploy Fluentd and Splunk using docker compose. This way, obtaining docker images, setting up configurations and running the applications can be done easily.

. Create `Dockerfile` to install essential packages while building Fluentd docker image. You need to install *build-essential* to install all dependencies and *fluent-plugin-splunk-enterprise* in order to forward the logs to Splunk.
* Sample `Dockerfile`:
+
```
# fluentd/Dockerfile
FROM fluent/fluentd:v1.10-debian
user 0
RUN apt-get update -y
RUN apt-get install build-essential -y
RUN fluent-gem install fluent-plugin-splunk-enterprise -v 0.10.0
```
+

. Create `docker-compose.yaml` file for Fluentd and Splunk deployment on your external machine.
* Sample `docker-compose.yaml`:
+
```
version: '3'

services:
  splunk:
    hostname: splunk
    image: splunk/splunk:8.0.5
    environment:
      SPLUNK_START_ARGS: --accept-license
      SPLUNK_ENABLE_LISTEN: 8088
      SPLUNK_PASSWORD: changeme
    volumes:
      - opt-splunk-etc:/opt/splunk/etc
      - opt-splunk-var:/opt/splunk/var
    ports:
      - "8000:8000" 
      - "8088:8088"

  fluentd:
    build: ./fluentd
    volumes:
      - ./fluentd/conf:/fluentd/etc
    links:
      - "splunk"
    ports:
      - "24224:24224"
      - "24224:24224/udp"
```
+
Configure the ports for Splunk and Fluentd. You can also define splunk password under *splunk: environment*.

. Deploy Splunk first to generate HTTP Event Collector token for Fluentd.
+
[source]
----
[root@ocp ~]# docker-compose up splunk
----
+

. Follow the instruction on link:https://openliberty.io/blog/2020/05/27/how-to-analyze-open-liberty-logs-with-splunk.html[How to analyze Open Liberty Logs with Splunk] in section, *Configuring the HTTP Event Collector*. Set *Name* as "openshift". Copy the generated token value.

. Create `fluentd.conf` file to configure Fluentd.
* Sample `fluentd.conf`:
+
```
<source>
  @type forward
  port 24224
</source>

<match kubernetes.**>
  @type splunk_hec
  host splunk-fluentd-forward.offcluster.com
  port 8088
  token 00000000-0000-0000-0000-0000000000000

  # metadata parameter
  default_source openshift

  use_ssl true
  ca_file /path/to/ca.pem
</match>
```
+
*source* directive determines the input sources. It uses *forward* type to accept TCP packets from your OpenShift Container Platform. *match* directive determines the output destinations. It looks for events with matching tags and uses *splunk_hec* to sends the events to Splunk using HTTP Event Collector. Splunk's *host* and *port* are required. *token* should be replaced by Splunk's generated token. Set *use_ssl* to true to use SSL when connecting to Splunk.

. Create `secure-forward.conf` to use the Fluentd forward protocol.
* Sample `secure-forward.conf`:
+
```
<store>
  @type forward
  <security>
    self_hostname ${hostname}
  </security>

  transport tls
  tls_verify_hostname false

  tls_cert_path '/etc/ocp-forward/ca-bundle.crt'

  <server>
    host splunk-fluentd-forward.offcluster.com
    port 24224
  </server>
</store>
```
+
*store* plugin forwards the logs to specified outputs under *server* directive. Specify *transport* tls if you wish to enable TLS validation and specify the path to private CA certificate file using *tls_cert_path*.

. Login to your OpenShift through command line tool. Create a ConfigMap named *secure-forward* in the *openshift-logging* namespace from the configuration file:
+
[source]
----
[root@ocp ~]# oc create configmap secure-forward --from-file=secure-forward.conf -n openshift-logging
----
+
If you need to import secrets required for the receiver, also run the following command:
+
[source]
----
[root@ocp ~]# oc create secret generic secure-forward --from-file=<certFile>=cert_file_from_fluentd_receiver
----
+

. Refresh the *fluentd* Pods to apply the secure-forward secret and secure-forward ConfigMap:
+
[source]
----
oc delete pod --selector logging-infra=fluentd
----
+

=== Setting up Splunk Dashboard

. Go to Search & Reporting. Search for `index="openshift"` for *Option 1* and `source="openshift"` for *Option 2* to view logs from OpenShift Container Platform.

. Download Splunk dashboards for Open Liberty: link:https://github.com/WASdev/sample.dashboards/tree/master/Liberty/Splunk%208[Sample dashboard for Liberty using Splunk]. Import downloaded sample dashboards using *Source* option. Using this dashboard, you can visualize message, trace, and first failure data capture (FFDC) logging data collected from JSON logging in Open Liberty.

image::/img/blog/splunk-dashboard.png[Splunk-Dashboard,width=70%,align="center"]

== External Elasticsearch and Kibana configuration
Using `elasticsearch` output, you can forward logs to Elasticsearch cluster deployed on your external machine. You run Elasticsearch and Kibana with docker compose. This way, obtaining docker images, setting up configurations and bringing up the clusters can be done  using one YAML file.

. Create `docker-compose.yaml` file for Elasticsearch and Kibana deployment on your external machine.
* Sample `docker-compose.yaml`:
+
```
version: '3'
services:

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:5.6.16
    ports:
      - "9200:9200"
    volumes:
      - ./elasticsearch/data:/usr/share/elasticsearch/data
    networks:
      - elastic

  kibana:
    image: docker.elastic.co/kibana/kibana:5.6.16
    ports:
      - "5601:5601"
    networks:
      - elastic
```
+
Deploy Elasticsearch and Kibana.
+
[source]
----
[root@ocp ~]# docker-compose up
----
+

. Download Kibana dashboards for Open Liberty: link:https://github.com/OpenLiberty/open-liberty-operator/tree/master/deploy/dashboards/logging[Sample Kibana dashboards for Open Liberty]. Import downloaded sample dashboards in Kibana Management > Saved Objects.

image::/img/blog/kibana-dashboard.png[Kibana Dashboard,width=70%,align="center"]

== Conclusion
Application logging is one of the fundamental types of observability. It helps you monitor and find the problems on your servers easily. Using Log Forwarding API, you can use existing external enterprise log collection solutions for OpenShift Container Platform logs. We have now seen two popular log collection solutions: Splunk and Kibana. Both log analysis solutions allow you to aggregate and analyze log events from Open Liberty servers running on OpenShift Cluster Platform. 